{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c1e95ec5d69d2cec95a6932bccd3a4e139eabbe6ae58dfb747c300ffd346fdaf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "access_log = [{'time': '08:39:37', 'limit': 844404, 'address': '1.227.124.181'}, {'time': '13:13:35', 'limit': 543871, 'address': '198.51.139.193'}, {'time': '19:40:45', 'limit': 3021, 'address': '172.1.254.208'}, {'time': '18:57:16', 'limit': 67031769, 'address': '172.58.247.219'}, {'time': '21:17:13', 'limit': 9083, 'address': '124.144.20.113'}, {'time': '23:34:17', 'limit': 65913, 'address': '203.236.149.220'}, {'time': '13:58:05', 'limit': 1541474, 'address': '192.52.206.76'}, {'time': '10:52:00', 'limit': 11465607, 'address': '104.47.149.93'}, {'time': '14:56:12', 'limit': 109, 'address': '192.31.185.7'}, {'time': '18:56:35', 'limit': 6207, 'address': '2.228.164.197'}]"
   ]
  },
  {
   "source": [
    "In the code below we have a set of dictionaries with the same keys for each, a prime candidate for a CSV. We import the csv library, and then open a new CSV file in write-mode by passing the 'w' argument to the open() function.\n",
    "\n",
    "We then define the fields we’re going to be using into a variable called fields. We then instantiate our CSV writer object and pass two arguments. The first is logger_csv, the file handler object. The second is our list of fields fields which we pass to the keyword parameter fieldnames.\n",
    "\n",
    "Now that we’ve instantiated our CSV file writer, we can start adding lines to the file itself! First we want the headers, so we call .writeheader() on the writer object. This writes all the fields passed to fieldnames as the first row in our file. Then we iterate through our access_log of data. Each item in access_log is a dictionary with each field in fields as the keys. We call log_writer.writerow() with the item dictionaries which writes each line to the CSV file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fields = ['time', 'address', 'limit']\n",
    "with open(\"logger.csv\", \"w\") as logger_csv:\n",
    "    log_writer = csv.DictWriter(logger_csv, fields)\n",
    "    log_writer.writeheader()\n",
    "    for ele in access_log:\n",
    "        log_writer.writerow(ele)"
   ]
  },
  {
   "source": [
    "### Writing JSON File"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_payload = [\n",
    "  {'interesting message': 'What is JSON? A web application\\'s little pile of secrets.',\n",
    "   'follow up': 'But enough talk!'}\n",
    "]\n",
    "\n",
    "# We import the json module, open up a write-mode file under the variable data_json, and then use the json.dump() method to write to the file. json.dump() takes two arguments: first the data object, then the file object you want to save.\n",
    "import json\n",
    "with open('data.json', 'w') as data_json:\n",
    "    json.dump(data_payload, data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ]
}